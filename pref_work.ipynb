{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "from random import shuffle\n",
    "from itertools import combinations\n",
    "from threading import Lock, Thread\n",
    "from collections import MutableMapping, OrderedDict\n",
    "import time\n",
    "import pickle\n",
    "import zlib\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import garner as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segment:\n",
    "    \"\"\"\n",
    "    A short recording of agent's behaviour in the environment,\n",
    "    consisting of a number of video frames and the rewards it received\n",
    "    during those frames.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.frames = []\n",
    "        self.rewards = []\n",
    "        self.hash = None\n",
    "\n",
    "    def append(self, frame, reward = None):\n",
    "        self.frames.append(frame)\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def finalise(self, seg_id=None):\n",
    "        if seg_id is not None:\n",
    "            self.hash = seg_id\n",
    "        else:\n",
    "            # This looks expensive, but don't worry -\n",
    "            # it only takes about 0.5 ms.\n",
    "            self.hash = hash(np.array(self.frames).tobytes())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "    \n",
    "class CompressedDict(MutableMapping):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.store = dict()\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return pickle.loads(zlib.decompress(self.store[key]))\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.store[key] = zlib.compress(pickle.dumps(value))\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        del self.store[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.store)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.store)\n",
    "\n",
    "    def __keytransform__(self, key):\n",
    "        return key\n",
    "    \n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "class PrefDB(Dataset):\n",
    "    \"\"\"\n",
    "    A circular database of preferences about pairs of segments.\n",
    "    For each preference, we store the preference itself\n",
    "    (mu in the paper) and the two segments the preference refers to.\n",
    "    Segments are stored with deduplication - so that if multiple\n",
    "    preferences refer to the same segment, the segment is only stored once.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, maxlen):\n",
    "        self.segments = CompressedDict()\n",
    "        self.seg_refs = {}\n",
    "        self.prefs = []\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def append(self, s1, s2, pref):\n",
    "        k1 = hash(np.array(s1).tobytes())\n",
    "        k2 = hash(np.array(s2).tobytes())\n",
    "\n",
    "        for k, s in zip([k1, k2], [s1, s2]):\n",
    "            if k not in self.segments.keys():\n",
    "                self.segments[k] = s\n",
    "                self.seg_refs[k] = 1\n",
    "            else:\n",
    "                self.seg_refs[k] += 1\n",
    "\n",
    "        tup = (k1, k2, pref)\n",
    "        self.prefs.append(tup)\n",
    "\n",
    "        if len(self.prefs) > self.maxlen:\n",
    "            self.del_first()\n",
    "\n",
    "    def del_first(self):\n",
    "        self.del_pref(0)\n",
    "\n",
    "    def del_pref(self, n):\n",
    "        if n >= len(self.prefs):\n",
    "            raise IndexError(\"Preference {} doesn't exist\".format(n))\n",
    "        k1, k2, _ = self.prefs[n]\n",
    "        for k in [k1, k2]:\n",
    "            if self.seg_refs[k] == 1:\n",
    "                del self.segments[k]\n",
    "                del self.seg_refs[k]\n",
    "            else:\n",
    "                self.seg_refs[k] -= 1\n",
    "        del self.prefs[n]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prefs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        #return s1s, s2s, prefs\n",
    "        return [(self.segments[k1], self.segments[k2], prefs) for k1, k2, pref, in self.prefs[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrefBuffer:\n",
    "    def __init__(self, garner, db_train, db_val, maxlen = 1000, maxqlen = 5):\n",
    "        \n",
    "        self.garner = garner\n",
    "        self.train_db = db_train\n",
    "        self.val_db = db_val\n",
    "        self.val_fraction = self.val_db.maxlen / (self.val_db.maxlen +\n",
    "                                     self.train_db.maxlen)\n",
    "        \n",
    "        self.segments = OrderedDict()\n",
    "        \n",
    "        self.tested_pairs = set()\n",
    "        self.queue = {}\n",
    "        self.maxlen = maxlen\n",
    "        self.maxqlen = maxqlen\n",
    "        self.lock = Lock()\n",
    "        self.stop_run = False\n",
    "        \n",
    "        #returned = garner.get_backlog(limit=maxlen)\n",
    "        \n",
    "        #for uuid, val in returned.items():\n",
    "            \n",
    "            \n",
    "            \n",
    "            #self.lock.acquire(blocking=True)\n",
    "            \n",
    "            #if np.random.rand() < self.val_fraction:\n",
    "            #    self.val_db.append(val[0][0][:,:,:,0:3], val[0][1][:,:,:,0:3], 1 if val[1] else 0)\n",
    "            #else:\n",
    "            #    self.train_db.append(val[0][0][:,:,:,0:3], val[0][1][:,:,:,0:3],  1 if val[1] else 0)\n",
    "                \n",
    "            #self.lock.release()\n",
    "            \n",
    "    #Aquiring old currently not a good idea :/\n",
    "        \n",
    "        \n",
    "    def select_prefs(self):\n",
    "        segment_idxs = list(range(len(self.segments)))\n",
    "        shuffle(segment_idxs)\n",
    "        possible_pairs = combinations(segment_idxs, 2)\n",
    "        \n",
    "        keys = list(pref_buffer.segments.keys())\n",
    "        \n",
    "        for i1, i2 in possible_pairs: \n",
    "            s1, s2 = self.segments[keys[i1]], self.segments[keys[i2]]\n",
    "            if ((s1.hash, s2.hash) not in self.tested_pairs) and \\\n",
    "               ((s2.hash, s1.hash) not in self.tested_pairs):\n",
    "                self.tested_pairs.add((s1.hash, s2.hash))\n",
    "                self.tested_pairs.add((s2.hash, s1.hash))\n",
    "                return s1.hash, s2.hash\n",
    "        \n",
    "        \n",
    "    def recv_prefs(self):\n",
    "        result = self.garner.query()\n",
    "        \n",
    "        if len(result) != 0:\n",
    "            print('get')\n",
    "            for key, value in result.items():\n",
    "                k1, k2 = self.queue[key]\n",
    "                \n",
    "                if np.random.rand() < self.val_fraction:\n",
    "                    self.val_db.append(self.segments[k1].frames, self.segments[k2].frames, 1 if value else 0)\n",
    "                else:\n",
    "                    self.train_db.append(self.segments[k1].frames, self.segments[k2].frames, 1 if value else 0)\n",
    "            del self.queue[key]\n",
    "            \n",
    "    def put_prefs(self):\n",
    "        try:\n",
    "            while len(self.queue) <= self.maxqlen:\n",
    "                print('put')\n",
    "                k1, k2 = self.select_prefs()\n",
    "                pref_id = self.garner.put([np.array(copy.deepcopy(self.segments[k1]).frames), \n",
    "                                           np.array(copy.deepcopy(self.segments[k1]).frames)], False)\n",
    "                self.queue[pref_id] = (k1, k2)\n",
    "        except:\n",
    "            print('No prefs to compare')\n",
    "        \n",
    "    def run(self):\n",
    "        while not self.stop_run:\n",
    "            time.sleep(1)\n",
    "            self.put_prefs()\n",
    "            self.recv_prefs()\n",
    "            \n",
    "    def start_thread(self):\n",
    "        self.stop_run = False\n",
    "        self.garner.connect()\n",
    "        Thread(target=self.run).start()\n",
    "        #self.run()\n",
    "        \n",
    "    def stop_thread(self):\n",
    "        self.stop_recv = True\n",
    "        self.garner.disconnect()\n",
    "    \n",
    "    def get_dbs(self):\n",
    "        self.lock.acquire(blocking=True)\n",
    "        train_copy = copy.deepcopy(self.train_db)\n",
    "        val_copy = copy.deepcopy(self.val_db)\n",
    "        self.lock.release()\n",
    "        return train_copy, val_copy\n",
    "    \n",
    "    def add_segment(self, segment):\n",
    "        \n",
    "        k = segment.hash\n",
    "        \n",
    "        self.segments[k] = copy.deepcopy(segment)\n",
    "        \n",
    "        if len(self.segments) > self.maxlen:\n",
    "            self.del_first()\n",
    "\n",
    "\n",
    "    def del_first(self):\n",
    "        print(self.segments)\n",
    "        del self.segments[next(iter(self.segments))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated\n"
     ]
    }
   ],
   "source": [
    "g.login('kipgparker@gmail.com')\n",
    "g.select_pool('Deep reinforcement learning from human prefrences')\n",
    "\n",
    "\n",
    "pref_db_train = PrefDB(maxlen=20000)\n",
    "pref_db_val = PrefDB(maxlen=5000)\n",
    "pref_buffer = PrefBuffer(garner = g, db_train=pref_db_train,\n",
    "                 db_val=pref_db_val, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pref_buffer.start_thread()\n",
    "\n",
    "import gym\n",
    "import cv2\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "segment = Segment()\n",
    "\n",
    "observation = env.reset()\n",
    "for _ in range(300):\n",
    "    img = env.render(mode='rgb_array') \n",
    "    action = env.action_space.sample() # your agent here (this takes random actions)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "\n",
    "    segment.append(cv2.resize(img, dsize=(300,200)))\n",
    "    \n",
    "    if done:\n",
    "        segment.finalise()\n",
    "        pref_buffer.add_segment(segment)\n",
    "        \n",
    "        segment = Segment()\n",
    "        observation = env.reset()\n",
    "env.close()\n",
    "\n",
    "#pref_buffer.stop_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected\n",
      "put\n",
      "put\n",
      "put\n",
      "put\n",
      "put\n",
      "put\n",
      "get\n",
      "put\n",
      "get\n",
      "put\n",
      "get\n",
      "put\n",
      "get\n",
      "put\n",
      "get\n",
      "put\n",
      "get\n",
      "put\n",
      "get\n",
      "put\n",
      "get\n",
      "put\n"
     ]
    }
   ],
   "source": [
    "pref_buffer.start_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disconnected\n"
     ]
    }
   ],
   "source": [
    "pref_buffer.stop_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = pref_buffer.get_dbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f0287a5b2f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms1s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b409536aad1c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m#return s1s, s2s, prefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-b409536aad1c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m#return s1s, s2s, prefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "for s1s, s2s, prefs in train:\n",
    "    print(s1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4014994444739598383"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pref_buffer.segments.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1f75e89-db70-4302-bdcd-7d028ef5d97d\n"
     ]
    }
   ],
   "source": [
    "for key, val in b.items():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {'f1f75e89-db70-4302-bdcd-7d028ef5d97d': [True]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gym' has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fe28fae2995c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gym' has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "gym.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a74a6daa-928e-429e-90b4-98771d39c732'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.put([np.array(segment.frames), np.array(segment.frames)], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.storage.download_file('protected/eu-west-2:7cb8b3ea-737d-4479-91b7-103ca54cf28d/77210b95-1dd7-49f6-92f9-23310a80c51a.gif', 'download.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out['4cd7869b-0abc-499c-91d0-d36b4a48c004'][0][0][0,:,:,3].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
